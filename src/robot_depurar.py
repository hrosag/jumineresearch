import os
from datetime import datetime

import pandas as pd
from supabase import create_client

# ---------------------------------------------------------------------
# VariÃ¡veis de ambiente fornecidas pelo GitHub Actions
# ---------------------------------------------------------------------
SUPABASE_URL = os.environ["SUPABASE_URL"]
SUPABASE_SERVICE_KEY = os.environ["SUPABASE_SERVICE_KEY"]

# cria cliente Supabase com permissÃ£o de service key
supabase = create_client(SUPABASE_URL, SUPABASE_SERVICE_KEY)

# ---------------------------------------------------------------------
# FunÃ§Ã£o que processa um Ãºnico arquivo .txt e devolve lista de dicts
#   -> cada dict = uma linha para a tabela all_data
# ---------------------------------------------------------------------
def parse_txt(content: str, source_file: str) -> list[dict]:
    """
    Exemplo didÃ¡tico: assume que cada bloco de 2 linhas no TXT contÃ©m:
       1Âª linha: nome da empresa
       2Âª linha: ticker
    Ajuste esta funÃ§Ã£o conforme a estrutura real dos boletins.
    """
    linhas = [l.strip() for l in content.splitlines() if l.strip()]
    registros = []
    block_id = 0
    for i in range(0, len(linhas), 2):
        try:
            company = linhas[i]
            ticker = linhas[i + 1] if i + 1 < len(linhas) else ""
        except IndexError:
            continue

        registros.append({
            "source_file": source_file,
            "block_id": block_id,
            "company": company,
            "ticker": ticker,
            "bulletin_type": "auto",            # ajuste conforme necessÃ¡rio
            "bulletin_date": datetime.utcnow().date().isoformat(),
            "tier": "parsed"
        })
        block_id += 1

    return registros

# ---------------------------------------------------------------------
# FunÃ§Ã£o principal: lÃª todos os .txt no bucket "uploads" e grava no all_data
# ---------------------------------------------------------------------
def main():
    print("ğŸš€ Iniciando depuraÃ§Ã£oâ€¦")

    # lista arquivos no bucket "uploads"
    files = supabase.storage.from_("uploads").list()
    if not files:
        print("âš ï¸ Nenhum arquivo encontrado no bucket 'uploads'.")
        return

    total_registros = 0

    for f in files:
        if not f["name"].lower().endswith(".txt"):
            continue

        print(f"ğŸ“‚ Processando {f['name']}â€¦")
        # baixa o conteÃºdo do arquivo
        data = supabase.storage.from_("uploads").download(f["name"])
        text = data.decode("utf-8")

        # faz o parse e monta os registros
        registros = parse_txt(text, f["name"])
        if not registros:
            print(f"âš ï¸ Nenhum registro extraÃ­do de {f['name']}.")
            continue

        # insere no Supabase
        supabase.table("all_data").insert(registros).execute()
        total_registros += len(registros)
        print(f"âœ… {len(registros)} registro(s) inserido(s) de {f['name']}.")

    print(f"ğŸ ConcluÃ­do. Total de registros inseridos: {total_registros}")

# ---------------------------------------------------------------------
if __name__ == "__main__":
    main()
